{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58efc689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semtorch in /opt/conda/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied: scikit-image<1.0.0,>=0.17.2 in /opt/conda/lib/python3.7/site-packages (from semtorch) (0.18.3)\n",
      "Requirement already satisfied: fastai<3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from semtorch) (2.5.4)\n",
      "Requirement already satisfied: torchvision<1.0.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from semtorch) (0.11.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from semtorch) (4.61.2)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from semtorch) (1.10.0)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from semtorch) (7.27.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from semtorch) (3.4.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.5 in /opt/conda/lib/python3.7/site-packages (from semtorch) (1.21.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (5.4.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (0.0.5)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (21.0.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (1.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (21.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (1.7.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (1.3.4)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.27 in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (1.3.28)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (1.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (2.25.1)\n",
      "Requirement already satisfied: pillow>6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (8.4.0)\n",
      "Requirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai<3.0.0,>=2.0.0->semtorch) (3.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image<1.0.0,>=0.17.2->semtorch) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image<1.0.0,>=0.17.2->semtorch) (1.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image<1.0.0,>=0.17.2->semtorch) (2.10.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image<1.0.0,>=0.17.2->semtorch) (2021.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->semtorch) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->semtorch) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->semtorch) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->semtorch) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->semtorch) (1.16.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (8.0.13)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (1.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (0.7.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (58.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (3.10.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (1.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (3.6.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fastai<3.0.0,>=2.0.0->semtorch) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fastai<3.0.0,>=2.0.0->semtorch) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fastai<3.0.0,>=2.0.0->semtorch) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fastai<3.0.0,>=2.0.0->semtorch) (1.26.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (8.0.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (4.8.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (0.18.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (5.1.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (2.10.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (0.1.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (3.0.20)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->semtorch) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->semtorch) (0.8.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->semtorch) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->semtorch) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<4->fastai<3.0.0,>=2.0.0->semtorch) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->fastai<3.0.0,>=2.0.0->semtorch) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai<3.0.0,>=2.0.0->semtorch) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->fastai<3.0.0,>=2.0.0->semtorch) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.widgets import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "!pip install semtorch\n",
    "from fastai.basics import *\n",
    "from fastai.vision import models\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback import *\n",
    "\n",
    "# SemTorch\n",
    "from semtorch import get_segmentation_learner\n",
    "\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c5a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My file path is being desing to look like this one. \n",
    "path = Path(\"../dataset2/\")\n",
    "#image is a normal microscope image. It's in png format. \n",
    "path_images = path/\"Images\"\n",
    "#labels are the masks balck and white. In tif format. \n",
    "path_labels = path/\"Labels\"\n",
    "\n",
    "test_name = \"test\"\n",
    "manual_name=\"manual\"\n",
    "\n",
    "path_manual_img = path_images/manual_name\n",
    "path_manual_lbl = path_labels/manual_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fcbfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../dataset2/Images/RT4')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2 = path_images/\"RT4\"\n",
    "path2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dad735",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_the_seed = 100\n",
    "\n",
    "random.seed(number_of_the_seed)\n",
    "set_seed(number_of_the_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a761d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_manual = get_image_files(path_manual_img)\n",
    "lbl_names_manual = get_image_files(path_manual_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070f1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_y_fn = lambda x: path_labels/manual_name/f'Mask_{str(x.stem[-3:])}.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cefda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParentSplitter(x):\n",
    "    return Path(x).parent.name==test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc1002eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose,\n",
    "    OneOf,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    Flip,\n",
    "    Rotate,\n",
    "    Transpose,\n",
    "    CLAHE,\n",
    "    ShiftScaleRotate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10d8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationAlbumentationsTransform(ItemTransform):\n",
    "    split_idx = 0\n",
    "    def __init__(self, aug): \n",
    "        self.aug = aug\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "        aug = self.aug(image=np.array(img), mask=np.array(mask))\n",
    "        return PILImage.create(aug[\"image\"]), PILMask.create(aug[\"mask\"])\n",
    "    \n",
    "transformPipeline=Compose([\n",
    "                        Flip(p=0.5),\n",
    "                        Transpose(p=0.5),\n",
    "                        Rotate(p=0.40,limit=10)\n",
    "                    ],p=1)\n",
    "\n",
    "transformPipeline=SegmentationAlbumentationsTransform(transformPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a221552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetMaskConvertTransform(ItemTransform):\n",
    "    def __init__(self): \n",
    "        pass\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "        \n",
    "        #Convert to array\n",
    "        mask = np.array(mask)\n",
    "        \n",
    "        # Change 255 for 1\n",
    "        mask[mask==255]=1\n",
    "        \n",
    "        # Back to PILMask\n",
    "        mask = PILMask.create(mask)\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b4f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrnet_splitter(model):\n",
    "    return [params(model.backbone), params(model.head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "254c0276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NoSpheroid': 0, 'Spheroid': 1}\n"
     ]
    }
   ],
   "source": [
    "codes = np.loadtxt(path/'codes.txt',dtype=str)\n",
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "print(name2id)\n",
    "void_code = name2id['NoSpheroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b03ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(inp, targ, axis):\n",
    "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
    "    pred,targ = flatten_check(inp.argmax(dim=axis), targ)\n",
    "    \n",
    "    #the mask is the targ pixels different from NoSpheroid\n",
    "    mask = targ != void_code\n",
    "    #[0]\n",
    "    #when the predicted pixels and targets pixels named spheroid correlates, we calculate the mean. \n",
    "    return (pred[mask] == targ[mask]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d7d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_name=\"manual\"\n",
    "camvid = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y=get_y_fn,\n",
    "                   splitter=RandomSplitter(valid_pct=0.1, seed=60),\n",
    "                   item_tfms=[Resize((160,160)),TargetMaskConvertTransform(), transformPipeline],\n",
    "                   batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5ec14",
   "metadata": {},
   "source": [
    "# Time to load the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd2ab5",
   "metadata": {},
   "source": [
    "Two options. If you are using UNet input the parameters of your models and run the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = camvid.dataloaders(path_manual_img, bs=32)\n",
    "learn = unet_learner(dls, resnet34, metrics=[accuracy, Dice(), JaccardCoeff()], self_attention=True, act_cls=Mish, opt_func=opt, wd=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80f09d",
   "metadata": {},
   "source": [
    "If SemTorch library has been used, customize this piece of code. Please, bear in mind:\n",
    "* Architecture \n",
    "* Backbone \n",
    "* WD \n",
    "* Cost function or loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d18cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:1051: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dls = camvid.dataloaders(path_images,bs=32)\n",
    "learn = get_segmentation_learner(dls=dls, number_classes=2, segmentation_type=\"Semantic Segmentation\",\n",
    "                                 architecture_name=\"hrnet\", backbone_name=\"hrnet_w48\", \n",
    "                                 metrics=[partial(pixel_accuracy, axis=1), Dice(), JaccardCoeff()], wd=1e-3,\n",
    "                                 splitter=hrnet_splitter, loss_func= DiceLoss(axis=1, smooth=1, reduction='mean', square_in_union=False)).to_fp16()\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa09ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/fastai/learner.py:56: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/4 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 39, in fetch\n    data = next(self.dataset_iter)\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\", line 118, in create_batches\n    yield from map(self.do_batch, self.chunkify(res))\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/basics.py\", line 217, in chunked\n    res = list(itertools.islice(it, chunk_sz))\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\", line 133, in do_item\n    try: return self.after_item(self.create_item(s))\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\", line 140, in create_item\n    if self.indexed: return self.dataset[s or 0]\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 332, in __getitem__\n    res = tuple([tl[it] for tl in self.tls])\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 332, in <listcomp>\n    res = tuple([tl[it] for tl in self.tls])\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 298, in __getitem__\n    return self._after_item(res) if is_indexer(idx) else res.map(self._after_item)\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 260, in _after_item\n    def _after_item(self, o): return self.tfms(o)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 200, in __call__\n    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 150, in compose_tfms\n    x = f(x, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 73, in __call__\n    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 83, in _call\n    return self._do_call(getattr(self, fn), x, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 89, in _do_call\n    return retain_type(f(x, **kwargs), x, ret)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/dispatch.py\", line 118, in __call__\n    return f(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/vision/core.py\", line 110, in create\n    return cls(load_image(fn, **merge(cls._open_args, kwargs)))\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/vision/core.py\", line 85, in load_image\n    im = Image.open(fn)\n  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 2975, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/notebooks/tumour_adapted/dataset2/Labels/manual/Mask__90.tif'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_873/3109091921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HRNet_Aug_wd3_model_2_hrnet_w48_bs_32_Dice_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, ds_idx, dl, cbs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_record'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 39, in fetch\n    data = next(self.dataset_iter)\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\", line 118, in create_batches\n    yield from map(self.do_batch, self.chunkify(res))\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/basics.py\", line 217, in chunked\n    res = list(itertools.islice(it, chunk_sz))\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\", line 133, in do_item\n    try: return self.after_item(self.create_item(s))\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/load.py\", line 140, in create_item\n    if self.indexed: return self.dataset[s or 0]\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 332, in __getitem__\n    res = tuple([tl[it] for tl in self.tls])\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 332, in <listcomp>\n    res = tuple([tl[it] for tl in self.tls])\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 298, in __getitem__\n    return self._after_item(res) if is_indexer(idx) else res.map(self._after_item)\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/data/core.py\", line 260, in _after_item\n    def _after_item(self, o): return self.tfms(o)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 200, in __call__\n    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 150, in compose_tfms\n    x = f(x, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 73, in __call__\n    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 83, in _call\n    return self._do_call(getattr(self, fn), x, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/transform.py\", line 89, in _do_call\n    return retain_type(f(x, **kwargs), x, ret)\n  File \"/opt/conda/lib/python3.7/site-packages/fastcore/dispatch.py\", line 118, in __call__\n    return f(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/vision/core.py\", line 110, in create\n    return cls(load_image(fn, **merge(cls._open_args, kwargs)))\n  File \"/opt/conda/lib/python3.7/site-packages/fastai/vision/core.py\", line 85, in load_image\n    im = Image.open(fn)\n  File \"/opt/conda/lib/python3.7/site-packages/PIL/Image.py\", line 2975, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '/notebooks/tumour_adapted/dataset2/Labels/manual/Mask__90.tif'\n"
     ]
    }
   ],
   "source": [
    "learn.load(\"HRNet_Aug_wd3_model_2_hrnet_w48_bs_32_Dice_loss\")\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c0189",
   "metadata": {},
   "source": [
    "Run this if you had built learners. It creates a datablock with the testing images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c7db42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2899/3807284453.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimagenet_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock),get_items = get_image_files, item_tfms=Resize((160,160)), batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
    "learn.dls =  dblock.dataloaders(path2, bs=7, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382a066",
   "metadata": {},
   "source": [
    "Finally to make prediction in bulk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import ntpath\n",
    "for file in path.ls():\n",
    "    #os.mkdir('Predicted_masks_HRNet')\n",
    "    filename = os.path2.basename(file)\n",
    "    if \"jpg\" in os.path2.basename(file):\n",
    "        trial = ntpath.basename(file)\n",
    "        #learn.inf\n",
    "        preds =learn.inf.predict(file)\n",
    "        pred_1 = preds[0][1]\n",
    "        pred_arx = pred_1.numpy()\n",
    "        rescaled = (755.0 / pred_arx.max() * (pred_arx - pred_arx.min())).astype(np.uint8)\n",
    "        im = Image.fromarray(rescaled) \n",
    "        for i in filename:\n",
    "            if i.isupper() == True:\n",
    "                identificator = filename.split(i)[0]\n",
    "                break\n",
    "        name = identificator + \"_Mask_\" + trial[-6:-4] + \".tif\"\n",
    "        im.save(f\"Predicted_masks_HRNet/{name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b169af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
